<configuration>
  <weiflow>
    <node id="1" preid="-1">DataConf</node>
    <node id="2" preid="-1">FeatureConf</node>
    <node id="3" preid="-1">GenSample</node>
    <node id="4" preid="-1">Glint_Training</node>
  </weiflow>
  <nodes>
    <node name="DataConf">
      <env>
        <var>SPARK_HOME=/usr/local/spark2.1.0</var>
        <var>SCALA_HOME=/usr/local/scala2.11.5</var>
      </env>
      <runtime name="com.weibo.datasys.engine.spark.node.NodeSparkImpl">
        <binPath>/usr/local/spark/bin/spark-submit</binPath>
        <sparkArgs>
          --master spark://10.77.16.120:7077
          --deploy-mode client
          --total-executor-cores 20
          --executor-cores 2
          --executor-memory 8g
        </sparkArgs>
      </runtime>
      <execute>
        <type>pipeline</type>
      </execute>
      <input name="input1">
        <className>com.weibo.datasys.engine.spark.input.InputSparkDataMeta</className>
        <dataPath>meta</dataPath>
      </input>
      <output name="output1">
        <className>com.weibo.datasys.engine.spark.output.OutputSparkDataConf</className>
        <dependency>input1</dependency>
        <dataPath>v0-data-feed_data.conf</dataPath>
      </output>
    </node>
    <node name="FeatureConf">
      <env>
        <var>SPARK_HOME=/usr/local/spark2.1.0</var>
        <var>SCALA_HOME=/usr/local/scala2.11.5</var>
      </env>
      <runtime name="com.weibo.datasys.engine.spark.node.NodeSparkImpl">
        <binPath>/usr/local/spark/bin/spark-submit</binPath>
        <sparkArgs>
          --master spark://10.77.16.120:7077
          --deploy-mode client
          --total-executor-cores 20
          --executor-cores 2
          --executor-memory 8g
        </sparkArgs>
      </runtime>
      <execute>
        <type>pipeline</type>
      </execute>
      <input name="input1">
        <className>com.weibo.datasys.engine.spark.input.InputSparkDataConf</className>
        <dataPath>data.conf.new</dataPath>
      </input>
      <output name="output1">
        <className>com.weibo.datasys.engine.spark.output.OutputSparkFeatureConf</className>
        <dependency>input1</dependency>
        <dataPath>feature.conf.new</dataPath>
      </output>
    </node>
    <node name="GenSample">
      <env>
        <var>SPARK_HOME=/usr/local/spark2.1.0</var>
        <var>SCALA_HOME=/usr/local/scala2.11.5</var>
      </env>
      <runtime name="com.weibo.datasys.engine.spark.node.NodeSparkImpl">
        <binPath>/usr/local/spark/bin/spark-submit</binPath>
        <sparkArgs>
          --master yarn
          --deploy-mode client
          --num-executors 100
          --executor-cores 4
          --executor-memory 10g
          --driver-memory 10g
        </sparkArgs>
      </runtime>
      <execute>
        <type>pipeline</type>
      </execute>
      <input name="input1">
        <className>com.weibo.datasys.engine.spark.input.InputSparkText</className>
        <dataPath>/user/feed_weibo/warehouse/mds_feed_strategy_bigdata/dt=20170523</dataPath>
        <metaPath>push.meta</metaPath>
        <fieldDelimiter>\t</fieldDelimiter>
      </input>
      <process name="process1">
        <className>com.weibo.datasys.engine.spark.process.ProcessSparkDataClean</className>
        <dependency>input1</dependency>
        <dataPath>push.data.conf</dataPath>
      </process>
      <process name="process2">
        <className>com.weibo.datasys.engine.spark.process.ProcessSparkDataExtract</className>
        <dependency>process1</dependency>
        <dataPath>push.data.conf</dataPath>
      </process>
      <process name="process3">
        <className>com.weibo.datasys.engine.spark.process.ProcessSparkFeatureMapping</className>
        <dependency>process2</dependency>
        <dataPath>push.feature.conf</dataPath>
      </process>
      <output name="output1">
        <className>com.weibo.datasys.engine.spark.output.OutputSparkLibsvm</className>
        <dependency>process3</dependency>
        <dataPath>/user/feed_weibo/warehouse/mds_feed_strategy_bigdata_libsvm/dt=20170523.wulei3</dataPath>
        <format>text</format>
      </output>
    </node>
    <node name="Glint_Training">
      <env>
        <var>SPARK_HOME=/usr/local/spark2.1.0</var>
        <var>SCALA_HOME=/usr/local/scala2.11.5</var>
      </env>
      <runtime name="com.weibo.datasys.engine.spark.node.NodeSparkImpl">
        <binPath>/usr/local/spark/bin/spark-submit</binPath>
        <sparkArgs>
          --master yarn
          --deploy-mode client
          --executor-cores 20
          --num-executors 700
          --driver-memory 20G
          --executor-memory 25G
	  --conf spark.driver.maxResultSize=5G
	 --conf spark.driver.network.timeout=240s
        </sparkArgs>
      </runtime>
      <execute>
        <type>pipeline</type>
      </execute>
      <input name="input1">
        <className>com.weibo.datasys.engine.spark.input.InputSparkLibsvm</className>
        <dataPath>/user/feed_weibo/warehouse/haibo_mds_feed_strategy_emr/data_final/dt=2017{0311,0312,0315,0316,0319,0320,0323,0421,0422,0423}</dataPath>
        <metaPath>1000yi.meta</metaPath>
        <format>text</format>
        <fieldDelimiter></fieldDelimiter>
      </input>
      <output name="output1">
        <className>com.weibo.datasys.engine.spark.output.OutputSparkLRWithPSTrain</className>
        <dependency>input1</dependency>
        <dataPath>/data1/users/haibo11/dataflow_2.0/model/testing_model_1000yi</dataPath>
        <Eta>0.0000001</Eta>
        <IterationTimes>1</IterationTimes>
        <BatchSize>10000</BatchSize>
        <FeatureSize>1200000000</FeatureSize>
        <GlintMasterHost>emr-worker-1.cluster-40569</GlintMasterHost>
        <GlintTimeOut>600</GlintTimeOut>
        <GlintServerCount>150</GlintServerCount>
        <TrainSamplesRatio>0.9</TrainSamplesRatio>
      </output>
    </node>
  </nodes>
</configuration>
